{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = {'Atlanta Falcons':'atl','Buffalo Bills':'buf','Carolina Panthers':'car','Chicago Bears':'chi',\n",
    "         'Cincinnati Bengals':'cin','Cleveland Browns':'cle','Indianapolis Colts':'clt',\n",
    "         'Arizona Cardinals':'crd','Dallas Cowboys':'dal','Denver Broncos':'den','Detroit Lions':'det',\n",
    "         'Green Bay Packers':'gnb','Houston Texans':'htx','Jacksonville Jaguars':'jax',\n",
    "         'Kansas City Chiefs':'kan','Miami Dolphins':'mia','Minnesota Vikings':'min','New Orleans Saints':'nor',\n",
    "         'New England Patriots':'nwe','New York Giants':'nyg','New York Jets':'nyj','Tennessee Titans':'oti',\n",
    "         'Philadelphia Eagles':'phi','Pittsburgh Steelers':'pit','Oakland Raiders':'rai',\n",
    "         'Las Vegas Raiders':'rai','St. Louis Rams':'ram','Los Angeles Rams':'ram','Baltimore Ravens':'rav',\n",
    "         'San Diego Chargers':'sdg','Los Angeles Chargers':'sdg','Seattle Seahawks':'sea',\n",
    "         'San Francisco 49ers':'sfo','Tampa Bay Buccaneers':'tam','Washington Redskins':'was'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekofgame(game):\n",
    "    from datetime import timedelta, datetime as dt\n",
    "    day_of_week={2:0,3:1,4:2,5:3,6:4,0:5,1:6} #day of week starts on Wednesday\n",
    "    date = dt.strptime(game[0:8],'%Y%m%d')\n",
    "# .weekday() returns the day of the week for datetime.datetime   \n",
    "    beg_week = date - timedelta(days=day_of_week[date.weekday()])\n",
    "    fmt = lambda x: str(x) if x >= 10 else '0'+str(x)\n",
    "    return(fmt(beg_week.month)+fmt(beg_week.day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mapping(group,averaged):\n",
    "    d={}\n",
    "    keys = sorted(group['Week_Beg'].unique())\n",
    "    values = [i for i in range((averaged+1),(averaged+1)+len(keys))]\n",
    "    for key,value in zip(keys,values):\n",
    "        d[key] = value\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year(code):\n",
    "    if (code[4:6] == '01'):\n",
    "        year = str(int(code[0:4])-1)\n",
    "    else:\n",
    "        year = str(int(code[0:4]))\n",
    "    return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_codes(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        codes = pickle.load(f)\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_codes(codes,yr):\n",
    "    subset = [codes[i] for i in range(len(codes)) if get_year(codes[i]) == yr]\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_weights(n,a=0):\n",
    "    arr = np.exp(a*np.arange(n))\n",
    "    return n*arr/np.sum(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_week(df,num):\n",
    "    by_week = pd.DataFrame(index=df.index,columns=['Week_Beg','Year','Week'])\n",
    "    for ind in by_week.index: \n",
    "        by_week.loc[ind,'Week_Beg'] = weekofgame(ind)\n",
    "        by_week.loc[ind,'Year'] = get_year(ind)\n",
    "    grouped_by_year = by_week.groupby(by_week['Year'])\n",
    "    for key, item in grouped_by_year:\n",
    "        mapping = get_mapping(item,num)\n",
    "        for code in item.index:\n",
    "            by_week.loc[code,'Week'] = int(mapping[by_week.loc[code,'Week_Beg']])\n",
    "    by_week['Week'] = by_week['Week'].astype('int')\n",
    "    df['Week'] = by_week['Week']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_scores(df,dfyear):\n",
    "# Take only the predicted games from dfyear\n",
    "    codes = set(dfyear.index.levels[1]).intersection(df.index)\n",
    "    for code in codes:\n",
    "        home = code[-3:]\n",
    "        df.loc[code,'Vis_Team'] = dfyear.loc[(home,code),'Opponent']\n",
    "        df.loc[code,'V_Game'] = dfyear.loc[(home,code),'Points_Opp']\n",
    "        df.loc[code,'Home_Team'] = \\\n",
    "            dfyear.loc[(teams[df.loc[code,'Vis_Team']],code),'Opponent']\n",
    "        df.loc[code,'H_Game'] = dfyear.loc[(home,code),'Points']\n",
    "        df.loc[code,'Tot_Pts'] = dfyear.loc[(home,code),'Points'] + dfyear.loc[(home,code),'Points_Opp']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_col_name(col):\n",
    "    seg = col.split('_')\n",
    "    newcol = col.replace(seg[-1],'Pct')\n",
    "    return newcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pct(df,conv,att):\n",
    "    prefix = ['H_','V_']\n",
    "    for pref in prefix:\n",
    "        col_conv = pref+conv\n",
    "        col_att = pref+att\n",
    "        col_new=replace_col_name(col_conv)\n",
    "        ind_no=df[df[col_att]==0].index\n",
    "        df.loc[ind_no,col_new] = 0.0\n",
    "        ind = df[df[col_att]!=0].index\n",
    "        df.loc[ind,col_new] = df.loc[ind,col_conv]/df.loc[ind,col_att]\n",
    "        df.drop([col_conv,col_att],axis=1,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_games(df,source,num):\n",
    "    hdictmap = {'Points':'H_Pts','Points_Opp':'H_Pts_Opp','Yds_Off_Pass':'H_Off_Pass',\n",
    "                'Yds_Off_Rush':'H_Off_Rush','Yds_Def_Pass':'H_Def_Pass','Yds_Def_Rush':'H_Def_Rush','TD':'H_TD',\n",
    "                'TD_on_Def':'H_TD_on_Def','FG_Made':'H_FG_Made','FG_Att':'H_FG_Att','RZ_Conv':'H_RZ_Conv',\n",
    "                'RZ_Att':'H_RZ_Att','RZ_Def_Conv':'H_RZ_Def_Conv','RZ_Def_Att':'H_RZ_Def_Att',\n",
    "                'Possession':'H_Poss','Plays':'H_Plays','TO_Gained':'H_TO_Gain','TO_Lost':'H_TO_Lost',\n",
    "                'Yds_Pen':'H_Yds_Pen','Sacks_Def':'H_Sacks_Def','Tackles_Loss':'H_Tackles_Loss',\n",
    "                'Yds_per_Kickret':'H_Kickret','Yds_per_Puntret':'H_Puntret'}\n",
    "    vdictmap = {'Points':'V_Pts','Points_Opp':'V_Pts_Opp','Yds_Off_Pass':'V_Off_Pass',\n",
    "                'Yds_Off_Rush':'V_Off_Rush','Yds_Def_Pass':'V_Def_Pass','Yds_Def_Rush':'V_Def_Rush','TD':'V_TD',\n",
    "                'TD_on_Def':'V_TD_on_Def','FG_Made':'V_FG_Made','FG_Att':'V_FG_Att','RZ_Conv':'V_RZ_Conv',\n",
    "                'RZ_Att':'V_RZ_Att','RZ_Def_Conv':'V_RZ_Def_Conv','RZ_Def_Att':'V_RZ_Def_Att',\n",
    "                'Possession':'V_Poss','Plays':'V_Plays','TO_Gained':'V_TO_Gain','TO_Lost':'V_TO_Lost',\n",
    "                'Yds_Pen':'V_Yds_Pen','Sacks_Def':'V_Sacks_Def','Tackles_Loss':'V_Tackles_Loss',\n",
    "                'Yds_per_Kickret':'V_Kickret','Yds_per_Puntret':'V_Puntret'}\n",
    "    wt_factor = 0\n",
    "    wt = normalize_weights(num,wt_factor)\n",
    "    for team in source.index.levels[0]:  # Fill in mean values of statistical categories\n",
    "        source.loc[team].sort_index(inplace=True)\n",
    "        for row in range(num,len(source.loc[team])):\n",
    "            code = source.loc[team].index[row]\n",
    "            if team == code[-3:]:\n",
    "                for key in hdictmap:\n",
    "                    df.loc[code,hdictmap[key]] = \\\n",
    "                        (source.loc[team].iloc[row-num:row,source.columns.get_loc(key)]*wt).mean() # Averaged over num games\n",
    "            else: \n",
    "                for key in vdictmap:\n",
    "                    df.loc[code,vdictmap[key]] = \\\n",
    "                        (source.loc[team].iloc[row-num:row,source.columns.get_loc(key)]*wt).mean()\n",
    "                    \n",
    "    for row in range(num,16):       # Calculate rank categories\n",
    "        opass = [(source.loc[team].iloc[row-num:row,source.columns.get_loc('Yds_Off_Pass')]*wt).mean() \n",
    "                 for team in source.index.levels[0]]\n",
    "        oprnk = pd.Series(opass,index=source.index.levels[0]).rank()\n",
    "        orush = [(source.loc[team].iloc[row-num:row,source.columns.get_loc('Yds_Off_Rush')]*wt).mean() \n",
    "                 for team in source.index.levels[0]]\n",
    "        orrnk = pd.Series(orush,index=source.index.levels[0]).rank()\n",
    "        dpass = [(source.loc[team].iloc[row-num:row,source.columns.get_loc('Yds_Def_Pass')]*wt).mean() \n",
    "                 for team in source.index.levels[0]]\n",
    "        dprnk = pd.Series(dpass,index=source.index.levels[0]).rank(ascending=False)\n",
    "        drush = [(source.loc[team].iloc[row-num:row,source.columns.get_loc('Yds_Def_Rush')]*wt).mean() \n",
    "                 for team in source.index.levels[0]]\n",
    "        drrnk = pd.Series(drush,index=source.index.levels[0]).rank(ascending=False)\n",
    "        for team in source.index.levels[0]:\n",
    "            if row < len(source.loc[team]): \n",
    "                code = source.loc[team].index[row]\n",
    "                if team == code[-3:]: \n",
    "                    df.loc[code,'H_O_Pass_Rank'] = oprnk[team]\n",
    "                    df.loc[code,'H_O_Rush_Rank'] = orrnk[team]\n",
    "                    df.loc[code,'H_D_Pass_Rank'] = dprnk[team]\n",
    "                    df.loc[code,'H_D_Rush_Rank'] = drrnk[team]\n",
    "                else: \n",
    "                    df.loc[code,'V_O_Pass_Rank'] = oprnk[team]\n",
    "                    df.loc[code,'V_O_Rush_Rank'] = orrnk[team]\n",
    "                    df.loc[code,'V_D_Pass_Rank'] = dprnk[team]\n",
    "                    df.loc[code,'V_D_Rush_Rank'] = drrnk[team]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats_metrics(df):\n",
    "    df['H_Pass_Metric'] = (df['H_O_Pass_Rank'] + df['V_D_Pass_Rank'])/2.0\n",
    "    df['H_Rush_Metric'] = (df['H_O_Rush_Rank'] + df['V_D_Rush_Rank'])/2.0\n",
    "    df['V_Pass_Metric'] = (df['V_O_Pass_Rank'] + df['H_D_Pass_Rank'])/2.0\n",
    "    df['V_Rush_Metric'] = (df['V_O_Rush_Rank'] + df['H_D_Rush_Rank'])/2.0\n",
    "    df.drop(['H_O_Pass_Rank','H_O_Rush_Rank','V_O_Pass_Rank','V_O_Rush_Rank','V_D_Pass_Rank','V_D_Rush_Rank',\n",
    "               'H_D_Pass_Rank','H_D_Rush_Rank'],axis=1,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dome(df):\n",
    "    df['dome'] = ((df['Temperature'] == 70) & (df['Wind'] == 0))*1\n",
    "    special = ['201909220kan','201611060sfo','200311240tam','200810260car','200911150was']\n",
    "    for code in special:\n",
    "        if code in df.index:\n",
    "            df.loc[code,'dome'] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windchill(df):\n",
    "# Wind chill factor for temperature when T <= 50 Â°F and wind > 3 mph\n",
    "    ind = df[(df['Temperature'] <= 50) & (df['Wind'] > 3)].index\n",
    "    df.loc[ind,'Temperature'] = (35.74 + 0.6215*df.loc[ind,'Temperature'] - \n",
    "                                35.75*(df.loc[ind,'Wind']**0.16) + \n",
    "                                0.4275*df.loc[ind,'Temperature']*(df.loc[ind,'Wind']**0.16))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "codepath = 'data/gamecodes.data'\n",
    "gcodes = get_codes(codepath)\n",
    "\n",
    "# Game Info\n",
    "ginfo = pd.DataFrame(index=gcodes,\n",
    "                     columns=['Over_Under','Temperature','Wind','Surface','Week','Year','dome'])\n",
    "for gamecode in gcodes:\n",
    "    year = get_year(gamecode)\n",
    "    path = 'data/raw/'+year+'/'+gamecode+'.pkl'\n",
    "    f = open(path, 'rb')\n",
    "    table = pickle.load(f)\n",
    "    table = pickle.load(f)\n",
    "    table = table.set_index(table.columns[0])\n",
    "    ginfo.loc[gamecode,'Surface'] = table.loc['Surface',1]\n",
    "    ginfo.loc[gamecode,'Over_Under'] = float(table.loc['Over/Under',1].split(' ')[0])\n",
    "    if 'Weather' in table.index:\n",
    "        string = table.loc['Weather',1]\n",
    "        ginfo.loc[gamecode,'Temperature'] = int(string.split(' ')[0])\n",
    "        if 'mph' in string:\n",
    "            for substr in string.split(','):\n",
    "                if 'mph' in substr:\n",
    "                    ginfo.loc[gamecode,'Wind'] = int(''.join(filter(str.isdigit, substr)))\n",
    "        else:\n",
    "            ginfo.loc[gamecode,'Wind'] = 0\n",
    "#         if 'humidity' in string:\n",
    "#             for substr in string.split(','):\n",
    "#                 if 'humidity' in substr:\n",
    "#                     ginfo.loc[gamecode,'Humidity'] = int(''.join(filter(str.isdigit, substr)))\n",
    "#         else:\n",
    "#             ginfo.loc[gamecode,'Humidity'] = 0\n",
    "    else:\n",
    "#         ginfo.loc[gamecode,'Humidity'] = 0 \n",
    "        ginfo.loc[gamecode,'Wind'] = 0\n",
    "    f.close()\n",
    "    ginfo.loc[gamecode,'Year'] = int(year)\n",
    "# Actual game temperatures manually entered\n",
    "special={'201912290jax':74,'201912080jax':68,'201912010jax':83,'201912010mia':82,\n",
    "       '201911100gnb':36,'201911100cle':53,'201911030sdg':77,'201910270jax':84,\n",
    "       '201909220kan':79,'201812090sdg':72,'201712100jax':55,'201610230nyj':62,\n",
    "       '201512130nyj':66,'200010080mia':87,'200012100kan':25}\n",
    "for key in special.keys():\n",
    "    if key in ginfo.index:\n",
    "        ginfo.loc[key,'Temperature'] = special[key]\n",
    "# Imputed for dome games\n",
    "ginfo['Temperature']=ginfo['Temperature'].fillna(70)\n",
    "ginfo = windchill(ginfo)\n",
    "ginfo = add_dome(ginfo)    \n",
    "#ginfo['dome'] = ginfo['dome'].astype('int')\n",
    "ginfo = add_week(ginfo,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End\n"
     ]
    }
   ],
   "source": [
    "num = 5 # number of games averaged over\n",
    "\n",
    "cols = ['Home_Team','Vis_Team','H_Game','V_Game','Tot_Pts','H_Pts','H_Pts_Opp','V_Pts','V_Pts_Opp',\n",
    "        'H_Off_Pass','H_O_Pass_Rank','V_Off_Pass','V_O_Pass_Rank','H_Off_Rush','H_O_Rush_Rank','V_Off_Rush',\n",
    "        'V_O_Rush_Rank','H_Def_Pass','H_D_Pass_Rank','V_Def_Pass','V_D_Pass_Rank','H_Def_Rush','H_D_Rush_Rank',\n",
    "        'V_Def_Rush','V_D_Rush_Rank','H_TD','V_TD','H_TD_on_Def','V_TD_on_Def','H_FG_Made','V_FG_Made',\n",
    "        'H_FG_Att','V_FG_Att','H_RZ_Conv','V_RZ_Conv','H_RZ_Att','V_RZ_Att','H_RZ_Def_Conv','V_RZ_Def_Conv',\n",
    "        'H_RZ_Def_Att','V_RZ_Def_Att','H_Poss','V_Poss','H_Plays','V_Plays','H_TO_Gain','V_TO_Gain','H_TO_Lost',\n",
    "        'V_TO_Lost','H_Yds_Pen','V_Yds_Pen','H_Sacks_Def','V_Sacks_Def','H_Tackles_Loss','V_Tackles_Loss',\n",
    "        'H_Kickret','V_Kickret','H_Puntret','V_Puntret']\n",
    "dfgame=pd.DataFrame(columns=cols)\n",
    "dfgame.index.set_names('Code',inplace=True)\n",
    "years=[str(year) for year in range(2010,2020)]\n",
    "for year in years:\n",
    "    path = 'data/df_step2_'+year+'.pkl'\n",
    "    with open(path, 'rb') as f:\n",
    "        dfyear = pickle.load(f)\n",
    "    dfgame = average_games(dfgame,dfyear,num)\n",
    "    dfgame = add_scores(dfgame,dfyear)\n",
    "dfgame = dfgame.join(ginfo,how='left')\n",
    "dfgame.dropna(inplace=True)\n",
    "dfgame = compute_stats_metrics(dfgame)\n",
    "dfgame = compute_pct(dfgame,'FG_Made','FG_Att')\n",
    "dfgame = compute_pct(dfgame,'RZ_Conv','RZ_Att')\n",
    "dfgame = compute_pct(dfgame,'RZ_Def_Conv','RZ_Def_Att')\n",
    "\n",
    "new_cols = ['Home_Team','Vis_Team','H_Game','V_Game','Over_Under','Tot_Pts','H_Pts',\n",
    "            'H_Pts_Opp','V_Pts','V_Pts_Opp','H_Off_Pass','H_Pass_Metric','V_Off_Pass',\n",
    "            'V_Pass_Metric','H_Off_Rush','H_Rush_Metric','V_Off_Rush','V_Rush_Metric',\n",
    "            'H_Def_Pass','V_Def_Pass','H_Def_Rush','V_Def_Rush','H_TD','V_TD',\n",
    "            'H_TD_on_Def','V_TD_on_Def','H_FG_Pct','V_FG_Pct','H_RZ_Pct','V_RZ_Pct',\n",
    "            'H_RZ_Def_Pct','V_RZ_Def_Pct','H_Poss','V_Poss','H_Plays','V_Plays',\n",
    "            'H_TO_Gain','V_TO_Gain','H_TO_Lost','V_TO_Lost','H_Yds_Pen','V_Yds_Pen',\n",
    "            'H_Sacks_Def','V_Sacks_Def','H_Tackles_Loss','V_Tackles_Loss','H_Kickret',\n",
    "            'V_Kickret','H_Puntret','V_Puntret','Temperature','Wind','dome','Week','Year','Surface']\n",
    "dfgame = dfgame[new_cols]\n",
    "dfgame = pd.concat([dfgame.drop('Surface', axis = 1), pd.get_dummies(dfgame.Surface)], axis = 1)\n",
    "dfgame.drop('astroturf',axis=1,inplace=True)\n",
    "\n",
    "numer_cols = dfgame.columns[4:]\n",
    "for col in numer_cols:\n",
    "    dfgame[col] = pd.to_numeric(dfgame[col])\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/df_working5.pkl'\n",
    "with open(path, 'wb') as f:\n",
    "    pickle.dump(dfgame,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall = dfgame\n",
    "path = 'data/df_complete.pkl'\n",
    "with open(path, 'wb') as f:\n",
    "    pickle.dump(dfall,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='data/df_gameinfo00_09.pkl'\n",
    "with open(path, 'wb') as f:\n",
    "    pickle.dump(ginfo,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/df_2000_2009.pkl'\n",
    "with open(path, 'wb') as f:\n",
    "    pickle.dump(dfgame,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
